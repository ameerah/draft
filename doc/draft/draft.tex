%TC:macro \subtitle [header]
%TC:newcounter todo Number of TODOs
%TC:macro \todo [option:ignore]
%TC:macrocount \todo [todo]

\documentclass[draft]{sig-alternate-05-2015}
\makeatletter
\def\@copyrightspace{\relax}
\makeatother

\usepackage[inline]{enumitem}
\usepackage{pgfgantt}
\usepackage[figuresright]{rotating}
\usepackage{tabularx}

\usepackage[english]{babel}
\usepackage[english]{isodate}
\cleanlookdateon

\usepackage{hyperref}

\usepackage{ifdraft}
\usepackage{xifthen}
\usepackage{soul}
\usepackage{xcolor}
\newcommand{\todo}[1][]{\ifdraft{\ifthenelse{\isempty{#1}}{\hl{(TODO)}}{\hl{(TODO: #1)}}}{}}

\begin{document}
  
  \title{Placeholder Title}
  \author{
    \alignauthor
    Ameerah Allie\\
    \affaddr{University of Cape Town}\\
    \email{ameerah.allie@gmail.com}
  }
  \maketitle

\begin{abstract}
  \todo
  \begin{itemize}
    \item Background for project (TDDOnto from Maria and Agnieszka)
    \item Describe work carried out incl. methodology
    \item Identify need/purpose for work
    \begin{itemize}
      \item No systematic testing of reasoner performance
      \item No systematic comparison of reasoners on metrics like (ontology size, test type etc)
    \end{itemize}
    \item Describe results of experiment
    \item Indicate usefulness and significance of results/tests
  \end{itemize}
\end{abstract}

\begin{CCSXML}
	<ccs2012>
    <concept>
      <concept_id>10010147.10010178.10010187.10010195</concept_id>
      <concept_desc>Computing methodologies~Ontology engineering</concept_desc>
      <concept_significance>500</concept_significance>
    </concept>
    <concept>
      <concept_id>10011007.10011074.10011081</concept_id>
      <concept_desc>Software and its engineering~Software development process management</concept_desc>
      <concept_significance>500</concept_significance>
    </concept>
    <concept>
      <concept_id>10011007.10011074.10011099.10011102.10011103</concept_id>
      <concept_desc>Software and its engineering~Software testing and debugging</concept_desc>
      <concept_significance>100</concept_significance>
    </concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Computing methodologies~Ontology engineering}
\ccsdesc[500]{Software and its engineering~Software development process management}
\ccsdesc[100]{Software and its engineering~Software testing and debugging}

\printccsdesc

\keywords{Ontology engineering; test-driven development; reasoners; benchmarking}

\section{Introduction}
\todo
\begin{itemize}
  \item Give background to project
  \item Describe scope of document and project
  \item Include explanation, summary and discussion of work
  \begin{itemize}
    \item includes why project is significant and its aims
  \end{itemize}
\end{itemize}

\section{Related Works}

Ontology authoring, especially when low-level, does not have many methodologies to assist with development. In particular, there is assistance at the micro-level with the use of established Ontology Design Patterns, FORZA and other tools and processes but there is ``no systematic testbed \ldots to implement the [Competency Question] in the authoring process'' \cite{DBLP:journals/corr/KeetL15}. This indicates the need for exploration of low-level methodologies for ontology authoring.

We are particularly concerned with the application of the test-driven development methodology to the development cycle of ontologies with regard to inserting axioms generated from Competency Questions (CQs) into an ontology. Test-driven development is an established methodology for low-level software development which has in many studied cases improved software quality \cite{DBLP:journals/infsof/BissiNE16}. 

Ontology development can benefit from applying the test-driven development process to the insertion of axioms into ontologies. The work of Keet and \L{}awrynowicz works towards defining and applying tests of ontologies for test-driven development of ontologies \cite{DBLP:journals/corr/KeetL15,DBLP:conf/esws/KeetL16}. The implementation of this \cite{DBLP:conf/dlog/LawrynowiczK16} and other tools in ontology development make use of reasoners \cite{DBLP:journals/corr/KeetL15}. This exposes a need for the testing and benchmarking of reasoners to determine when each one performs most efficiently in comparison to other reasoners, and to learn more about reasoner performance.

This section considers the related work of concepts introduced above: test-driven development, ontology authoring and the application of test-driven development to it, and current use and comparison of reasoners.

\subsection{Test-Driven Development in Software Development}

\subsubsection{The Test-Driven Development Process}

Test-driven development describes the process of developing software whereby code is continuously tested against unit tests throughout the development cycle, determining when new code can be added. For every new piece of functionality to be added to software, a unit test for that functionality must be written to test whether or not it already exists in the software. The functionality must necessarily fail the new test. Code for that functionality must be added and the software must pass all previous unit tests and the new test. The code may be refactored if necessary and tests should be rerun to ensure that the refactoring has not changed the code's behaviour \cite{kumar2013comparative,DBLP:journals/infsof/PancurC11}.

This describes a test-first approach \cite{DBLP:journals/infsof/BissiNE16} where coding is necessarily done in increments ensuring that errors caught by failed tests are picked up quickly through constant testing \cite{DBLP:journals/iee/MullerH02}.

\subsubsection{The Benefits of Test-Driven Development}

In a paper by Bissi \textit{et al} \cite{DBLP:journals/infsof/BissiNE16}, their review of 1127 papers on test-driven development published between 1999 and 2014 indicated that most studies an increase in internal software quality and in external software quality. By separating functionality into smaller tasks, high granularity is imposed on the code. M\"{u}ller and Hagner ascribe the increase in software quality to this granularity --- the modularity of the code makes the code easier to work with \cite{DBLP:journals/iee/MullerH02}. It also makes programmers immediately aware of issues in the code and forces the programmer to fix it promptly.

Pan\v{c}ur and Ciglari\v{c} claim that studies on test-driven development like those done by M\"{u}ller and examined by Bissi have not had many controlled experiments to confirm the successes \cite{DBLP:journals/infsof/PancurC11}. Furthermore, they suggest that the improved code may be attributable not to the notion of a test-first approach but to the granularity of code and that this is not made clear in previous studies.

 M\"{u}ller and Hagner, however, had conducted a controlled experiment \cite{DBLP:journals/iee/MullerH02}. Acknowledging the difficulties of evaluating test-driven development outside of extreme programming (the methodology out of which test-driven development rose), they found that there was no significant difference in programming time and reliability of code but there was improved understanding of code. Better understanding of code may improve code design. George and Williams more successfully evaluated test-driven development outside of extreme programming and found that test-driven development increased coding time but improved code quality \cite{DBLP:journals/infsof/GeorgeW04}.
 
 While the reasons for it may not be known as Pan\v{c}ur and Ciglari\v{c} suggest \cite{DBLP:journals/infsof/PancurC11}, the large majority of studies demonstrate an improvement in code quality (internal or external) \cite{DBLP:journals/infsof/BissiNE16} and understanding yet differ on whether or not test-driven development improves efficiency \cite{DBLP:journals/infsof/GeorgeW04,DBLP:journals/iee/MullerH02}.

\subsection{Ontology Authoring and Test-Driven Development}

There are existing methodologies for ontology development which provide high-level guidance for development like Methontology \cite{fernandez1997methontology}, NeOn \cite{DBLP:journals/ao/Suarez-Figueroa15} and the use of Ontology Design Patterns \cite{DBLP:conf/semweb/PresuttiDGB09}. These may assist with formalising scope, making design choices for the ontology, or other high-level actions but they do not help the ontology engineer with inserting axioms into the ontology.

Previous studies on test-driven development were often concerned with implementing test-driven development in situations where alternative development methodologies already existed. This is not the case with ontology authoring where there is no real existing, alternative methodology at low-level development \cite{DBLP:journals/corr/KeetL15}. Current approaches are test-last approaches or adding code and seeing if the reasoner being used does not have a problem with it \cite{DBLP:conf/esws/KeetL16}.

Test-driven development is a desirable methodology to apply to ontology development since it can provide a systematic testbed by which code can be tested. It could possibly improve code understanding and quality.

Current efforts into applying the test-driven development methodology include Tort, Oliv\'{e} and Sancho's application of it to conceptual schemas \cite{DBLP:journals/dke/TortOS11}. Structurally, a conceptual schema is similar to an ontology in that it consists of a taxonomy of entities, relationships and constraints. In this tool, not much time was spent on writing test cases but principle of feature addition testing could be applied to ontologies.

For low-level ontology authoring, ontology developers typically use the reasoner and the Foundational Ontology and Reasoner-enhanced axiomatiZAtion (FORZA) to insert axioms into the ontology, or previously mentioned Ontology Design Patterns as guidance \cite{DBLP:conf/esws/KeetL16}. Often, new axioms added to existing, maintained ontologies are accepted simply if they do not cause an inconsistency \cite{DBLP:journals/ws/NikitinaRG12}. However, there is no standard set of tests or a testbed that may be applied to this level of ontology authoring. Developers insert their axiom in a haphazard fashion and check whether or not the reasoner accepts the given input. There is also no assurance of quality on this. This is because it is ``difficult to either specify the requirements for an ontology, or test their satisfaction'' according to Ren \textit{et al} \cite{DBLP:conf/esws/RenPMPDS14}.

\subsection{Reasoner Use and Comparison}

\todo

\section{Materials and Methodology}

An experiment was designed to measure the performance of different reasoners. The experiment design is detailed below along with materials used to carry out the experiment.

\subsection{Experiment Overview}
The aim of the the experiment is to benchmark reasoners, specifically within the context of Test-Driven Development of Ontologies. This requires the use of ``unit tests'' on which reasoners are used. These unit tests have been previously defined in the work of Keet and \L{}awrynowicz \cite{DBLP:conf/esws/KeetL16}. New test harnesses are constructed around these pre-defined unit tests. Each of these tests are performed on the same set of ontologies and each test is timed. These speeds for each reasoner allow us to measure how fast each reasoner performs against different ontology properties, like type of axiom and ontology size (detailed below).

The development of the test harnesses and their integration with different reasoners were done in two phases: the test harnesses were first developed on a personal computer, and tested and edited there to ensure that they terminated and ran correctly; the tests were then run on the University of Cape Town cluster\footnote{\url{http://hex.uct.ac.za}} to ensure consistent testing conditions for accurate results.

\subsection{Materials}
\todo

\subsection{Methodology}
\todo

\subsubsection{Implementation of Benchmarking Tests}
\todo

\subsubsection{Analysis of Test Results}
\todo

\section{Results}
\todo
\begin{itemize}
  \item Show results
  \item Include text to link results together
\end{itemize}

\section{Discussion}
\todo
\begin{itemize}
  \item Look at results, explain them and their significance
  \item Evaluate project
  \begin{itemize}
    \item Consider what was done well, what could be improved on and specify future work
  \end{itemize}
\end{itemize}

\section{Conclusions}
\todo

\newpage
\bibliographystyle{abbrv}
\bibliography{references}
\end{document}